{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c896d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41eb489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with gzip.open(\"../dataset0.json.gz\", \"rt\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f821b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"../data.info.labelled\")\n",
    "label_dict = {\n",
    "    (row.transcript_id, row.transcript_position): row.label\n",
    "    for row in df_labels.itertuples(index=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4cb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_and_position(data):\n",
    "    id = list(data.keys())[0]\n",
    "    position = list(data[id].keys())[0]\n",
    "    return id, position\n",
    "\n",
    "def get_features(data):\n",
    "    id, position = get_id_and_position(data)\n",
    "    return list(data[id][position].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd024295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.00299, 2.06, 125.0, 0.0177, 10.4, 122.0, 0.0093, 10.9, 84.1],\n",
       " [0.00631, 2.53, 125.0, 0.00844, 4.67, 126.0, 0.0103, 6.3, 80.9],\n",
       " [0.00465, 3.92, 109.0, 0.0136, 12.0, 124.0, 0.00498, 2.13, 79.6],\n",
       " [0.00398, 2.06, 125.0, 0.0083, 5.01, 130.0, 0.00498, 3.78, 80.4],\n",
       " [0.00664, 2.92, 120.0, 0.00266, 3.94, 129.0, 0.013, 7.15, 82.2],\n",
       " [0.0103, 3.83, 123.0, 0.00598, 6.45, 126.0, 0.0153, 1.09, 74.8],\n",
       " [0.00398, 3.75, 126.0, 0.00332, 4.3, 129.0, 0.00299, 1.93, 81.9],\n",
       " [0.00498, 3.93, 127.0, 0.00398, 2.51, 131.0, 0.0111, 3.47, 79.4],\n",
       " [0.0139, 4.69, 106.0, 0.0136, 6.21, 124.0, 0.00531, 10.6, 85.5],\n",
       " [0.00631, 3.5, 126.0, 0.0222, 5.38, 128.0, 0.00332, 1.72, 79.3],\n",
       " [0.0061, 3.99, 121.0, 0.0121, 7.27, 122.0, 0.00232, 1.27, 78.9],\n",
       " [0.00299, 1.99, 128.0, 0.00427, 4.85, 124.0, 0.00332, 3.18, 80.5],\n",
       " [0.0186, 3.62, 124.0, 0.00428, 2.25, 129.0, 0.00554, 2.78, 80.1],\n",
       " [0.0093, 3.12, 125.0, 0.00398, 8.84, 129.0, 0.00361, 1.86, 82.0],\n",
       " [0.00365, 2.92, 126.0, 0.00698, 3.7, 126.0, 0.00467, 3.23, 80.2],\n",
       " [0.0123, 6.68, 126.0, 0.00854, 11.9, 123.0, 0.00232, 1.37, 78.4],\n",
       " [0.0123, 5.04, 106.0, 0.0136, 9.34, 126.0, 0.00399, 3.28, 79.7],\n",
       " [0.00996, 2.96, 130.0, 0.00755, 12.2, 123.0, 0.0103, 5.5, 83.1],\n",
       " [0.0119, 8.61, 124.0, 0.00972, 7.92, 127.0, 0.00531, 1.07, 79.2],\n",
       " [0.011, 3.96, 126.0, 0.00395, 5.19, 127.0, 0.00564, 4.23, 83.0],\n",
       " [0.00291, 3.42, 125.0, 0.0133, 6.01, 127.0, 0.0027, 1.44, 79.0],\n",
       " [0.00863, 3.66, 128.0, 0.00489, 9.02, 127.0, 0.00332, 1.38, 74.2],\n",
       " [0.00299, 2.28, 126.0, 0.0126, 5.37, 127.0, 0.00332, 3.28, 81.1],\n",
       " [0.0176, 3.13, 129.0, 0.00715, 12.6, 125.0, 0.00996, 1.9, 79.1],\n",
       " [0.00963, 3.35, 122.0, 0.00614, 10.5, 127.0, 0.00332, 6.57, 77.5],\n",
       " [0.00432, 3.96, 122.0, 0.0073, 2.26, 128.0, 0.00398, 3.49, 76.9],\n",
       " [0.00764, 3.88, 108.0, 0.0093, 11.9, 124.0, 0.00975, 4.65, 81.4],\n",
       " [0.00299, 3.07, 128.0, 0.0165, 10.4, 128.0, 0.00332, 1.52, 83.5],\n",
       " [0.00648, 3.68, 123.0, 0.0136, 10.5, 127.0, 0.00764, 11.9, 84.6],\n",
       " [0.00432, 3.08, 126.0, 0.0064, 4.5, 128.0, 0.00564, 10.8, 81.7],\n",
       " [0.00531, 4.6, 123.0, 0.0084, 3.5, 126.0, 0.0204, 4.31, 79.3],\n",
       " [0.0123, 4.1, 126.0, 0.00664, 3.15, 124.0, 0.00372, 5.35, 81.9],\n",
       " [0.00232, 2.09, 127.0, 0.00332, 6.98, 123.0, 0.00996, 7.18, 82.1],\n",
       " [0.00398, 2.03, 128.0, 0.0219, 11.6, 124.0, 0.00797, 3.1, 81.4],\n",
       " [0.00797, 3.17, 126.0, 0.0025, 2.91, 126.0, 0.00716, 5.68, 82.0],\n",
       " [0.00809, 7.61, 123.0, 0.0073, 5.46, 127.0, 0.0147, 1.78, 78.2],\n",
       " [0.00863, 6.16, 123.0, 0.00299, 14.1, 126.0, 0.00299, 4.98, 81.8],\n",
       " [0.0116, 3.53, 124.0, 0.0213, 10.9, 126.0, 0.00755, 1.74, 79.4],\n",
       " [0.013, 9.26, 121.0, 0.0173, 9.2, 125.0, 0.00646, 4.83, 80.3],\n",
       " [0.00465, 3.08, 126.0, 0.00797, 12.9, 123.0, 0.00332, 11.6, 82.3],\n",
       " [0.0083, 4.03, 119.0, 0.0119, 3.24, 126.0, 0.00564, 3.34, 81.7],\n",
       " [0.013, 6.9, 127.0, 0.00398, 2.85, 133.0, 0.00486, 5.28, 79.4],\n",
       " [0.00498, 2.96, 127.0, 0.00465, 14.8, 111.0, 0.0073, 0.773, 79.2],\n",
       " [0.00631, 4.86, 127.0, 0.011, 8.07, 127.0, 0.0126, 6.24, 82.2],\n",
       " [0.0136, 8.83, 125.0, 0.0091, 13.9, 120.0, 0.012, 1.36, 77.8],\n",
       " [0.00432, 4.33, 126.0, 0.00984, 7.44, 125.0, 0.00664, 6.47, 82.1],\n",
       " [0.00365, 2.2, 124.0, 0.00664, 3.62, 128.0, 0.0107, 7.51, 82.0],\n",
       " [0.00299, 3.41, 125.0, 0.00583, 4.09, 127.0, 0.00232, 3.24, 79.0],\n",
       " [0.00896, 4.4, 132.0, 0.00413, 4.45, 125.0, 0.00266, 4.95, 79.4],\n",
       " [0.00498, 2.12, 128.0, 0.0115, 5.34, 126.0, 0.00498, 6.85, 82.0],\n",
       " [0.00332, 2.96, 127.0, 0.0146, 4.74, 126.0, 0.00516, 3.36, 80.2],\n",
       " [0.00498, 2.94, 126.0, 0.0058, 4.49, 127.0, 0.00531, 15.5, 88.3],\n",
       " [0.0126, 4.32, 127.0, 0.00534, 8.76, 131.0, 0.00558, 3.21, 80.5],\n",
       " [0.00718, 4.82, 122.0, 0.00232, 6.19, 124.0, 0.00309, 1.95, 80.6],\n",
       " [0.00664, 5.32, 107.0, 0.0213, 8.84, 126.0, 0.00449, 2.5, 81.6],\n",
       " [0.00421, 4.47, 124.0, 0.00674, 5.02, 128.0, 0.00716, 3.6, 78.7],\n",
       " [0.012, 3.44, 127.0, 0.0163, 8.8, 128.0, 0.00598, 6.58, 83.6],\n",
       " [0.0113, 4.59, 126.0, 0.00531, 3.46, 130.0, 0.00801, 4.14, 79.6],\n",
       " [0.00519, 7.44, 124.0, 0.00332, 2.89, 130.0, 0.0138, 2.49, 81.3],\n",
       " [0.0143, 4.03, 124.0, 0.0137, 9.85, 125.0, 0.0173, 8.11, 79.4],\n",
       " [0.0164, 9.48, 124.0, 0.00495, 10.9, 123.0, 0.013, 1.67, 75.7],\n",
       " [0.00631, 3.58, 121.0, 0.00884, 7.14, 126.0, 0.0116, 2.18, 78.8],\n",
       " [0.00583, 3.2, 122.0, 0.00365, 9.26, 127.0, 0.00564, 5.18, 81.3],\n",
       " [0.0107, 5.43, 122.0, 0.00469, 9.73, 123.0, 0.0073, 3.18, 80.9],\n",
       " [0.00332, 2.59, 127.0, 0.00603, 6.21, 125.0, 0.00631, 1.56, 80.6],\n",
       " [0.00896, 4.54, 127.0, 0.00232, 11.6, 121.0, 0.00598, 5.63, 78.3],\n",
       " [0.00365, 4.27, 129.0, 0.0136, 8.44, 126.0, 0.00699, 2.31, 80.5],\n",
       " [0.00704, 6.45, 123.0, 0.00362, 10.5, 122.0, 0.00332, 1.76, 80.0],\n",
       " [0.0248, 13.4, 122.0, 0.00863, 9.78, 126.0, 0.00598, 4.3, 74.4],\n",
       " [0.00398, 3.42, 125.0, 0.012, 13.5, 124.0, 0.0103, 5.29, 81.4],\n",
       " [0.00266, 3.41, 124.0, 0.00572, 5.79, 125.0, 0.00266, 1.52, 80.0],\n",
       " [0.00631, 4.3, 122.0, 0.00564, 5.2, 130.0, 0.011, 4.61, 80.7],\n",
       " [0.0123, 4.9, 122.0, 0.00598, 5.45, 129.0, 0.013, 8.94, 78.2],\n",
       " [0.00232, 4.12, 102.0, 0.0083, 10.9, 126.0, 0.00598, 3.7, 81.3],\n",
       " [0.00825, 7.57, 120.0, 0.00598, 10.8, 126.0, 0.00465, 6.85, 78.6],\n",
       " [0.00332, 2.7, 126.0, 0.0164, 7.37, 125.0, 0.012, 7.9, 81.4],\n",
       " [0.0136, 3.41, 128.0, 0.00834, 4.05, 128.0, 0.00996, 11.9, 84.2],\n",
       " [0.00266, 2.74, 127.0, 0.02, 6.55, 125.0, 0.00398, 4.47, 78.0],\n",
       " [0.00332, 2.96, 128.0, 0.0272, 8.88, 128.0, 0.0055, 2.56, 79.0],\n",
       " [0.0025, 4.55, 123.0, 0.015, 9.93, 125.0, 0.0111, 2.39, 78.6],\n",
       " [0.00465, 4.1, 126.0, 0.0116, 12.1, 123.0, 0.0103, 3.23, 74.9],\n",
       " [0.0116, 3.28, 124.0, 0.00671, 6.65, 124.0, 0.00631, 5.25, 80.8],\n",
       " [0.00232, 2.63, 118.0, 0.0089, 6.36, 127.0, 0.0242, 6.27, 82.1],\n",
       " [0.00232, 3.59, 128.0, 0.0089, 4.51, 126.0, 0.0123, 8.42, 85.3],\n",
       " [0.00465, 2.99, 128.0, 0.00478, 6.72, 123.0, 0.00835, 1.88, 78.6],\n",
       " [0.0163, 3.44, 124.0, 0.00607, 4.34, 125.0, 0.0153, 7.18, 82.2],\n",
       " [0.00697, 4.69, 124.0, 0.0296, 12.2, 122.0, 0.00712, 2.94, 78.6],\n",
       " [0.0106, 3.28, 125.0, 0.0123, 11.0, 125.0, 0.00432, 1.78, 77.9],\n",
       " [0.00863, 5.26, 124.0, 0.00764, 15.7, 124.0, 0.00465, 1.52, 77.7],\n",
       " [0.00564, 2.36, 124.0, 0.00809, 7.06, 123.0, 0.00232, 1.38, 80.9],\n",
       " [0.00896, 3.37, 126.0, 0.0105, 10.7, 126.0, 0.00553, 2.82, 81.3],\n",
       " [0.00527, 8.66, 122.0, 0.0073, 10.0, 124.0, 0.00764, 4.85, 81.6],\n",
       " [0.0116, 3.14, 125.0, 0.015, 5.27, 127.0, 0.00775, 3.36, 79.7],\n",
       " [0.00457, 2.3, 124.0, 0.00323, 4.4, 127.0, 0.00929, 3.44, 79.6],\n",
       " [0.0083, 6.14, 124.0, 0.0147, 4.36, 126.0, 0.00963, 9.4, 83.9],\n",
       " [0.0059, 5.57, 126.0, 0.012, 11.2, 127.0, 0.00564, 9.24, 87.3],\n",
       " [0.012, 3.73, 124.0, 0.0252, 14.4, 123.0, 0.0051, 4.16, 81.2],\n",
       " [0.0135, 4.09, 126.0, 0.0054, 5.71, 127.0, 0.00396, 3.48, 81.4],\n",
       " [0.0083, 4.17, 121.0, 0.00973, 5.68, 124.0, 0.00316, 1.6, 81.8],\n",
       " [0.0064, 8.5, 122.0, 0.00531, 14.9, 117.0, 0.0103, 3.05, 76.1],\n",
       " [0.0153, 3.43, 125.0, 0.00697, 5.53, 127.0, 0.00531, 2.04, 78.1],\n",
       " [0.00498, 3.91, 125.0, 0.0116, 11.6, 127.0, 0.00797, 2.8, 80.8],\n",
       " [0.00963, 4.11, 122.0, 0.00859, 5.53, 125.0, 0.00531, 10.6, 83.8],\n",
       " [0.0073, 3.51, 125.0, 0.00721, 4.7, 126.0, 0.00299, 1.68, 79.4],\n",
       " [0.00365, 3.6, 125.0, 0.0061, 5.03, 129.0, 0.0149, 6.33, 82.1],\n",
       " [0.0196, 3.47, 126.0, 0.00352, 3.5, 127.0, 0.00498, 1.78, 78.9],\n",
       " [0.00299, 3.4, 128.0, 0.0159, 9.26, 126.0, 0.0103, 4.71, 79.1],\n",
       " [0.00764, 4.66, 106.0, 0.0139, 5.11, 126.0, 0.00885, 2.51, 80.9],\n",
       " [0.0163, 4.13, 125.0, 0.0126, 11.3, 127.0, 0.00744, 2.56, 78.5],\n",
       " [0.0266, 10.8, 125.0, 0.00332, 12.9, 115.0, 0.0073, 1.74, 78.8],\n",
       " [0.00266, 2.66, 125.0, 0.00536, 10.3, 123.0, 0.00478, 2.95, 78.2],\n",
       " [0.00598, 4.66, 104.0, 0.013, 11.0, 124.0, 0.0025, 1.13, 78.6],\n",
       " [0.00365, 2.98, 129.0, 0.0124, 6.14, 127.0, 0.0133, 3.13, 81.0],\n",
       " [0.011, 3.3, 122.0, 0.0132, 6.4, 129.0, 0.00694, 1.41, 79.5],\n",
       " [0.0083, 2.93, 127.0, 0.00666, 4.17, 125.0, 0.00299, 1.45, 78.0],\n",
       " [0.00531, 2.8, 125.0, 0.00656, 6.21, 128.0, 0.00598, 1.48, 80.9],\n",
       " [0.0126, 3.77, 128.0, 0.0043, 6.27, 125.0, 0.00465, 2.48, 80.4],\n",
       " [0.00531, 7.38, 120.0, 0.00664, 11.1, 126.0, 0.00398, 1.64, 79.2],\n",
       " [0.00896, 2.78, 123.0, 0.00432, 6.22, 126.0, 0.00232, 3.8, 85.3],\n",
       " [0.00465, 3.11, 126.0, 0.0143, 6.78, 128.0, 0.0103, 2.7, 80.4],\n",
       " [0.0073, 2.92, 126.0, 0.00925, 7.14, 126.0, 0.00552, 1.42, 78.3],\n",
       " [0.00365, 6.1, 120.0, 0.0036, 2.98, 128.0, 0.00232, 2.38, 78.4],\n",
       " [0.00398, 2.41, 127.0, 0.0192, 5.49, 128.0, 0.00382, 3.07, 80.0],\n",
       " [0.00903, 7.86, 124.0, 0.00332, 2.89, 130.0, 0.00365, 4.27, 78.8],\n",
       " [0.00896, 2.8, 125.0, 0.00724, 4.43, 128.0, 0.0159, 1.61, 82.2],\n",
       " [0.0172, 5.04, 126.0, 0.00232, 1.04, 132.0, 0.00797, 4.01, 81.1],\n",
       " [0.00963, 5.59, 126.0, 0.0118, 9.32, 126.0, 0.0227, 4.09, 79.8],\n",
       " [0.0259, 6.92, 127.0, 0.00365, 6.82, 123.0, 0.00432, 2.35, 79.1],\n",
       " [0.00957, 4.01, 119.0, 0.0123, 4.09, 130.0, 0.00963, 5.14, 76.9],\n",
       " [0.0252, 3.58, 126.0, 0.00644, 9.31, 126.0, 0.00631, 7.69, 82.4],\n",
       " [0.00531, 2.93, 127.0, 0.0101, 6.34, 126.0, 0.00332, 6.62, 85.7],\n",
       " [0.00598, 2.91, 125.0, 0.00835, 2.39, 130.0, 0.00511, 1.39, 79.6],\n",
       " [0.00332, 1.77, 128.0, 0.0127, 4.8, 128.0, 0.00633, 3.31, 76.8],\n",
       " [0.0133, 3.18, 126.0, 0.0176, 9.71, 126.0, 0.0146, 8.12, 82.9],\n",
       " [0.00963, 7.44, 124.0, 0.0073, 13.8, 124.0, 0.0186, 3.47, 78.2],\n",
       " [0.00797, 4.01, 127.0, 0.00674, 7.17, 130.0, 0.00564, 12.1, 85.6],\n",
       " [0.00794, 5.4, 123.0, 0.00764, 10.8, 126.0, 0.00875, 2.38, 80.0],\n",
       " [0.00797, 3.73, 126.0, 0.0149, 5.65, 126.0, 0.0123, 5.42, 83.5],\n",
       " [0.0139, 3.82, 123.0, 0.0145, 10.7, 125.0, 0.0123, 2.57, 81.9],\n",
       " [0.016, 10.2, 123.0, 0.00996, 12.2, 119.0, 0.00526, 5.19, 80.9],\n",
       " [0.0158, 8.17, 126.0, 0.0111, 8.37, 127.0, 0.0106, 1.77, 79.2],\n",
       " [0.00398, 3.84, 128.0, 0.0157, 8.19, 128.0, 0.00664, 8.7, 82.6],\n",
       " [0.00498, 3.3, 128.0, 0.00432, 6.55, 129.0, 0.00631, 5.55, 81.1],\n",
       " [0.0093, 3.0, 127.0, 0.0143, 7.0, 125.0, 0.00572, 3.26, 79.1],\n",
       " [0.00498, 4.63, 126.0, 0.0062, 5.29, 128.0, 0.00398, 9.0, 83.1],\n",
       " [0.0093, 3.01, 126.0, 0.0163, 10.9, 126.0, 0.00332, 1.64, 80.0],\n",
       " [0.00432, 5.61, 126.0, 0.00232, 8.13, 126.0, 0.00598, 10.9, 81.8],\n",
       " [0.0128, 7.44, 123.0, 0.019, 12.9, 123.0, 0.0329, 12.8, 87.4],\n",
       " [0.00232, 2.19, 121.0, 0.0083, 8.67, 120.0, 0.00365, 2.61, 74.6],\n",
       " [0.00365, 5.32, 123.0, 0.00725, 2.85, 127.0, 0.00266, 4.61, 81.7],\n",
       " [0.0073, 2.28, 123.0, 0.012, 8.69, 123.0, 0.00531, 4.19, 81.3],\n",
       " [0.0073, 2.44, 128.0, 0.00843, 3.42, 126.0, 0.00467, 5.44, 80.2],\n",
       " [0.00637, 7.33, 126.0, 0.00598, 4.46, 130.0, 0.00332, 7.06, 85.9],\n",
       " [0.00341, 3.75, 117.0, 0.00594, 4.35, 127.0, 0.00996, 9.79, 84.7],\n",
       " [0.0113, 3.64, 125.0, 0.00477, 3.81, 128.0, 0.00531, 1.58, 76.8],\n",
       " [0.00306, 3.45, 119.0, 0.00539, 5.7, 125.0, 0.00345, 5.97, 83.9],\n",
       " [0.00531, 3.47, 126.0, 0.00578, 10.2, 123.0, 0.00631, 9.75, 84.9],\n",
       " [0.0149, 4.09, 125.0, 0.0141, 9.44, 126.0, 0.00631, 1.52, 79.3],\n",
       " [0.00432, 5.28, 121.0, 0.00863, 7.89, 126.0, 0.00332, 3.96, 81.0],\n",
       " [0.0075, 3.13, 123.0, 0.0154, 3.97, 125.0, 0.013, 5.13, 80.7],\n",
       " [0.0339, 6.39, 124.0, 0.00613, 10.2, 123.0, 0.00316, 1.55, 77.6],\n",
       " [0.00398, 3.48, 129.0, 0.00628, 3.08, 130.0, 0.00885, 2.69, 81.8],\n",
       " [0.017, 2.71, 121.0, 0.00713, 3.29, 127.0, 0.0138, 5.61, 85.3],\n",
       " [0.00332, 2.54, 106.0, 0.0143, 10.5, 123.0, 0.00266, 5.29, 83.7],\n",
       " [0.00398, 5.44, 112.0, 0.0279, 9.95, 127.0, 0.00365, 1.63, 80.0],\n",
       " [0.0232, 3.45, 120.0, 0.0113, 11.1, 126.0, 0.0163, 8.75, 82.9],\n",
       " [0.00635, 3.24, 126.0, 0.0119, 4.56, 124.0, 0.011, 3.23, 80.5],\n",
       " [0.00797, 2.91, 127.0, 0.00459, 3.68, 127.0, 0.00682, 6.19, 82.5],\n",
       " [0.00199, 2.24, 126.0, 0.0073, 6.38, 128.0, 0.0146, 4.32, 82.6],\n",
       " [0.012, 2.8, 125.0, 0.00882, 7.61, 126.0, 0.00797, 8.75, 82.7],\n",
       " [0.00797, 3.92, 125.0, 0.0135, 7.47, 128.0, 0.00863, 4.55, 81.5],\n",
       " [0.00432, 6.8, 123.0, 0.00463, 2.68, 128.0, 0.00299, 6.85, 78.5],\n",
       " [0.00232, 3.72, 123.0, 0.00524, 11.0, 122.0, 0.00398, 1.66, 81.1],\n",
       " [0.00564, 2.47, 126.0, 0.00361, 4.68, 128.0, 0.00332, 5.93, 82.2],\n",
       " [0.012, 3.37, 128.0, 0.00465, 15.2, 124.0, 0.0107, 4.87, 82.3],\n",
       " [0.00432, 3.85, 126.0, 0.0081, 3.92, 126.0, 0.00398, 9.36, 85.3],\n",
       " [0.0116, 4.39, 108.0, 0.0173, 9.57, 124.0, 0.0126, 1.48, 77.3],\n",
       " [0.00531, 4.35, 125.0, 0.00533, 4.81, 128.0, 0.00365, 1.44, 78.7],\n",
       " [0.00697, 2.62, 126.0, 0.00583, 7.14, 129.0, 0.00232, 1.27, 77.2],\n",
       " [0.00266, 3.96, 123.0, 0.0174, 6.36, 128.0, 0.00232, 2.43, 78.8],\n",
       " [0.0242, 4.45, 124.0, 0.00564, 4.45, 128.0, 0.00365, 2.41, 73.1],\n",
       " [0.00557, 5.21, 126.0, 0.00266, 1.85, 129.0, 0.00896, 8.68, 79.0],\n",
       " [0.00764, 3.9, 124.0, 0.0063, 5.38, 123.0, 0.012, 2.69, 82.6],\n",
       " [0.00863, 3.46, 121.0, 0.00894, 6.27, 126.0, 0.00598, 1.52, 78.6],\n",
       " [0.0027, 4.45, 120.0, 0.018, 3.5, 125.0, 0.00498, 2.77, 82.1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895a3b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.506295244505\n",
      "minimum number of reads is 20\n"
     ]
    }
   ],
   "source": [
    "feature_length = []\n",
    "for i in data:\n",
    "    feature_length.append(len(get_features(i)))\n",
    "\n",
    "print(np.mean(feature_length))\n",
    "print(f\"minimum number of reads is {np.min(feature_length)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4679c72",
   "metadata": {},
   "source": [
    "Because the minimum number of reads in the data is 20, we try to get the first 20 reads so we have a constant input data of a matrix of 20*9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313a806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_reads(data, n_reads=20):\n",
    "    \"\"\"\n",
    "    Extracts the first n_reads from the list of reads in `data`.\n",
    "    Pads with zeros if there are fewer than n_reads.\n",
    "\n",
    "    Args:\n",
    "        data (list[list[float]]): Output from get_features(), list of read feature vectors (len = num_reads).\n",
    "        n_reads (int): Number of reads to keep. Default is 20.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of shape (n_reads, 9)\n",
    "    \"\"\"\n",
    "    # convert to numpy array\n",
    "    features = np.array(data, dtype=float)\n",
    "\n",
    "    # case 1: more reads than needed → take the first n_reads\n",
    "    if len(features) >= n_reads:\n",
    "        return features[:n_reads]\n",
    "\n",
    "    # case 2: fewer reads → pad with zeros\n",
    "    else:\n",
    "        pad_len = n_reads - len(features)\n",
    "        pad = np.zeros((pad_len, features.shape[1]))\n",
    "        return np.vstack((features, pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c80157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 9)\n"
     ]
    }
   ],
   "source": [
    "reads = get_features(data[0])\n",
    "fixed = get_top_reads(reads, n_reads=20)\n",
    "print(fixed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870c101",
   "metadata": {},
   "source": [
    "install torch if you dont have torch on your local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027f9241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp312-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.23.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.8.0-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [torchaudio]8\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.8.0 torchaudio-2.8.0 torchvision-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0317245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19cb8652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from scikit-learn) (2.3.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/yihewang/Downloads/vision_field_rating_api/venv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3b1b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for entry in data:\n",
    "    id, position = get_id_and_position(entry)\n",
    "    reads = get_features(entry)\n",
    "    fixed = get_top_reads(reads, n_reads=20)\n",
    "    label = label_dict.get((id, int(position)), None)\n",
    "    X.append(fixed)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9f6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_t   = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t   = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "val_ds   = TensorDataset(X_val_t, y_val_t)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "deb2c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 10, 64)  # after pooling 20 -> 10\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 20, 9)\n",
    "        x = x.permute(0, 2, 1)  # (batch, features, reads)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b19055e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "pos_weight = torch.tensor(\n",
    "    (len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    dtype=torch.float32  # force float32 for MPS\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b84dab",
   "metadata": {},
   "source": [
    "only execute the next section if you are on Apple silicon (M1-4 chips), so it will run on GPU via Metal Performance Shaders (MPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c80d14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = X_train_t.to(device)\n",
    "y_train_t = y_train_t.to(device)\n",
    "X_val_t   = X_val_t.to(device)\n",
    "y_val_t   = y_val_t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f853af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train loss=1.3079, Val loss=1.2900, ROC AUC=0.610, PR AUC=0.053\n",
      "Epoch 2/30, Train loss=1.2942, Val loss=1.2542, ROC AUC=0.649, PR AUC=0.060\n",
      "Epoch 3/30, Train loss=1.2057, Val loss=1.1584, ROC AUC=0.729, PR AUC=0.179\n",
      "Epoch 4/30, Train loss=1.0969, Val loss=1.1641, ROC AUC=0.766, PR AUC=0.148\n",
      "Epoch 5/30, Train loss=1.0667, Val loss=1.0408, ROC AUC=0.796, PR AUC=0.221\n",
      "Epoch 6/30, Train loss=1.0584, Val loss=1.1866, ROC AUC=0.754, PR AUC=0.146\n",
      "Epoch 7/30, Train loss=1.0467, Val loss=1.0511, ROC AUC=0.800, PR AUC=0.231\n",
      "Epoch 8/30, Train loss=1.0466, Val loss=1.0390, ROC AUC=0.799, PR AUC=0.220\n",
      "Epoch 9/30, Train loss=1.0347, Val loss=1.0211, ROC AUC=0.804, PR AUC=0.249\n",
      "Epoch 10/30, Train loss=1.0422, Val loss=1.1212, ROC AUC=0.776, PR AUC=0.170\n",
      "Epoch 11/30, Train loss=1.0376, Val loss=1.0939, ROC AUC=0.798, PR AUC=0.213\n",
      "Epoch 12/30, Train loss=1.0259, Val loss=1.0248, ROC AUC=0.804, PR AUC=0.251\n",
      "Epoch 13/30, Train loss=1.0253, Val loss=1.0153, ROC AUC=0.812, PR AUC=0.254\n",
      "Epoch 14/30, Train loss=1.0126, Val loss=1.0347, ROC AUC=0.803, PR AUC=0.237\n",
      "Epoch 15/30, Train loss=1.0185, Val loss=1.0699, ROC AUC=0.807, PR AUC=0.258\n",
      "Epoch 16/30, Train loss=1.0152, Val loss=1.0001, ROC AUC=0.814, PR AUC=0.276\n",
      "Epoch 17/30, Train loss=1.0062, Val loss=0.9936, ROC AUC=0.815, PR AUC=0.281\n",
      "Epoch 18/30, Train loss=1.0054, Val loss=1.0289, ROC AUC=0.804, PR AUC=0.256\n",
      "Epoch 19/30, Train loss=1.0041, Val loss=0.9888, ROC AUC=0.820, PR AUC=0.275\n",
      "Epoch 20/30, Train loss=1.0000, Val loss=1.0023, ROC AUC=0.810, PR AUC=0.269\n",
      "Epoch 21/30, Train loss=0.9925, Val loss=0.9822, ROC AUC=0.821, PR AUC=0.283\n",
      "Epoch 22/30, Train loss=0.9958, Val loss=0.9789, ROC AUC=0.824, PR AUC=0.285\n",
      "Epoch 23/30, Train loss=0.9890, Val loss=1.0132, ROC AUC=0.812, PR AUC=0.275\n",
      "Epoch 24/30, Train loss=0.9847, Val loss=0.9993, ROC AUC=0.817, PR AUC=0.283\n",
      "Epoch 25/30, Train loss=0.9802, Val loss=0.9791, ROC AUC=0.826, PR AUC=0.290\n",
      "Epoch 26/30, Train loss=0.9785, Val loss=1.0283, ROC AUC=0.815, PR AUC=0.243\n",
      "Epoch 27/30, Train loss=0.9763, Val loss=0.9863, ROC AUC=0.820, PR AUC=0.298\n",
      "Epoch 28/30, Train loss=0.9717, Val loss=1.0144, ROC AUC=0.819, PR AUC=0.281\n",
      "Epoch 29/30, Train loss=0.9753, Val loss=0.9643, ROC AUC=0.828, PR AUC=0.289\n",
      "Epoch 30/30, Train loss=1.0062, Val loss=1.0088, ROC AUC=0.810, PR AUC=0.242\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for Xb, yb in train_loader:\n",
    "        # move batch to device\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred_logits = model(Xb)  # raw logits, do NOT apply sigmoid here\n",
    "        loss = criterion(y_pred_logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # --- validation ---\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_logits = model(X_val_t)  # raw logits\n",
    "        val_loss = criterion(y_val_logits, y_val_t).item()\n",
    "        \n",
    "        # convert logits to probabilities for metrics\n",
    "        y_val_prob = torch.sigmoid(y_val_logits).detach().cpu().numpy()\n",
    "        y_val_true = y_val_t.detach().cpu().numpy()\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_val_true, y_val_prob)\n",
    "        pr_auc  = average_precision_score(y_val_true, y_val_prob)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train loss={total_loss/len(train_loader):.4f}, \"\n",
    "          f\"Val loss={val_loss:.4f}, \"\n",
    "          f\"ROC AUC={roc_auc:.3f}, PR AUC={pr_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5835c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.818, PR AUC: 0.287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "## for mac users to copy y_val back to memory\n",
    "y_val_pred_np = y_val_pred.detach().cpu().numpy()\n",
    "\n",
    "## if on windows: run \n",
    "## y_val_pred_np = y_val_pred.numpy()\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred_np)\n",
    "pr_auc = average_precision_score(y_val, y_val_pred_np)\n",
    "print(f\"ROC AUC: {roc_auc:.3f}, PR AUC: {pr_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
