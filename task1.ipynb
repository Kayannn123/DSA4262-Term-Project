{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15676d86",
   "metadata": {},
   "source": [
    "#### Model Structure\n",
    "- XGB Classifier\n",
    "- Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae92df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b68539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_line(obj):\n",
    "    (tid, tdata), = obj.items()\n",
    "    (pos_key, contexts), = tdata.items()\n",
    "    pos = int(pos_key) if isinstance(pos_key, str) else pos_key\n",
    "    (ctx7, reads), = contexts.items()\n",
    "    arr = np.asarray(reads, dtype=float)\n",
    "    return tid, pos, ctx7, arr\n",
    "\n",
    "BASE_IDX = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n",
    "def onehot28(seq7: str) -> np.ndarray:\n",
    "    out = np.zeros((7,4), dtype=np.int8)\n",
    "    s = (seq7 or \"\").upper()\n",
    "    for i in range(min(7, len(s))):\n",
    "        j = BASE_IDX.get(s[i], -1)\n",
    "        if j >= 0:\n",
    "            out[i, j] = 1\n",
    "    return out.ravel()\n",
    "\n",
    "def aggregate_9(arr: np.ndarray) -> np.ndarray:\n",
    "    if arr.size == 0:\n",
    "        return np.zeros(45, dtype=np.float32)\n",
    "    mean = arr.mean(axis=0)\n",
    "    std  = arr.std(axis=0, ddof=0)\n",
    "    mn   = arr.min(axis=0)\n",
    "    mx   = arr.max(axis=0)\n",
    "    med  = np.median(arr, axis=0)\n",
    "    return np.concatenate([mean, std, mn, mx, med]).astype(np.float32, copy=False)\n",
    "\n",
    "NUM_COLS = [\n",
    "    \"dwell_m1\",\"sd_m1\",\"mean_m1\",\n",
    "    \"dwell_0\",\"sd_0\",\"mean_0\",\n",
    "    \"dwell_p1\",\"sd_p1\",\"mean_p1\",\n",
    "]\n",
    "FEATURE_NAMES = (\n",
    "    [f\"mean_{c}\"   for c in NUM_COLS] +\n",
    "    [f\"std_{c}\"    for c in NUM_COLS] +\n",
    "    [f\"min_{c}\"    for c in NUM_COLS] +\n",
    "    [f\"max_{c}\"    for c in NUM_COLS] +\n",
    "    [f\"median_{c}\" for c in NUM_COLS] +\n",
    "    [f\"ctx_{i}\"    for i in range(28)]\n",
    ")\n",
    "\n",
    "\n",
    "def build_dataset_from_json_objects(json_objects, label_dict, transcript_to_gene):\n",
    "    \"\"\"\n",
    "    json_objects: iterable of parsed per-line dicts\n",
    "    label_dict: {(transcript_id, position): 0/1}\n",
    "    Returns X (N,73), y (N,), plus ids for later mapping.\n",
    "    \"\"\"\n",
    "    X_rows, y_rows, ids = [], [], []\n",
    "    for obj in json_objects:\n",
    "        tid, pos, ctx7, arr = parse_json_line(obj)\n",
    "        feats45 = aggregate_9(arr)\n",
    "        ctx28   = onehot28(ctx7)\n",
    "        X_rows.append(np.concatenate([feats45, ctx28]))\n",
    "        y_rows.append(label_dict.get((tid, int(pos)), None))\n",
    "        gene = transcript_to_gene.get((tid, None))\n",
    "        ids.append((gene, tid, int(pos)))\n",
    "    X = np.asarray(X_rows, dtype=np.float32)\n",
    "    y = np.asarray(y_rows)\n",
    "    return X, y, ids\n",
    "\n",
    "def make_data_splits(X, y, ids, test_size=0.3, val_size=0.5, random_state=4262):\n",
    "    mask = ~pd.isna(y)\n",
    "    X_tr = X[mask]\n",
    "    y_tr = y[mask].astype(int)\n",
    "\n",
    "    groups = np.array([\n",
    "        str(gene) if gene is not None else tid\n",
    "        for gene, tid, pos in ids\n",
    "    ])[mask]\n",
    "\n",
    "    gss = GroupShuffleSplit(test_size=test_size, random_state=random_state)\n",
    "    train_idx, temp_idx = next(gss.split(X_tr, y_tr, groups=groups))\n",
    "\n",
    "    gss2 = GroupShuffleSplit(test_size=val_size, random_state=random_state)\n",
    "    val_idx, test_idx = next(gss2.split(X_tr[temp_idx], y_tr[temp_idx], groups=groups[temp_idx]))\n",
    "\n",
    "    train_genes = set(groups[train_idx])\n",
    "    val_genes   = set(groups[temp_idx][val_idx])\n",
    "    test_genes  = set(groups[temp_idx][test_idx])\n",
    "    assert len(train_genes & val_genes) == 0, \"Gene overlap between train and val!\"\n",
    "    assert len(train_genes & test_genes) == 0, \"Gene overlap between train and test!\"\n",
    "    assert len(val_genes & test_genes) == 0, \"Gene overlap between val and test!\"\n",
    "    print(f\"Split complete: {len(train_genes)} train genes, {len(val_genes)} val genes, {len(test_genes)} test genes\")\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X[train_idx], \"y_train\": y[train_idx],\n",
    "        \"X_val\": X[temp_idx][val_idx], \"y_val\": y[temp_idx][val_idx],\n",
    "        \"X_test\": X[temp_idx][test_idx], \"y_test\": y[temp_idx][test_idx],\n",
    "        \"ids_train\": [ids[i] for i in train_idx],\n",
    "        \"ids_val\": [ids[i] for i in temp_idx[val_idx]],\n",
    "        \"ids_test\": [ids[i] for i in temp_idx[test_idx]]\n",
    "    }\n",
    "    \n",
    "\n",
    "def iter_json_lines(path: str):\n",
    "    \"\"\"Stream NDJSON from .json or .json.gz\"\"\"\n",
    "    p = Path(path)\n",
    "    if p.suffix == \".gz\":\n",
    "        with gzip.open(p, \"rt\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            for line in f:\n",
    "                s = line.strip()\n",
    "                if s:\n",
    "                    yield json.loads(s)\n",
    "    else:\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                s = line.strip()\n",
    "                if s:\n",
    "                    yield json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b4082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete: 3733 train genes, 800 val genes, 800 test genes\n"
     ]
    }
   ],
   "source": [
    "df_labels = pd.read_csv(\"data_task1/data.info.labelled.csv\")\n",
    "label_dict = { (r.transcript_id, int(r.transcript_position)): int(r.label) for r in df_labels.itertuples(index=False)}\n",
    "transcript_to_gene = dict(zip(df_labels['transcript_id'], df_labels['gene_id']))\n",
    "\n",
    "train_json_iter = iter_json_lines(\"data_task1/dataset0.json\")\n",
    "X, y, ids = build_dataset_from_json_objects(train_json_iter, label_dict, transcript_to_gene)\n",
    "data = make_data_splits(X, y, ids)\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "\n",
    "ids_train = data['ids_train']\n",
    "ids_val = data['ids_val']\n",
    "ids_test = data['ids_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55fb33",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e04767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_optuna(X_train, y_train, X_val, y_val, n_trials=40):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 7),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.03, 0.1, log=True),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 800),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.95),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 0.95),\n",
    "            \"scale_pos_weight\": trial.suggest_int(\"scale_pos_weight\", 10, 30),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 2, 6),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.05, 0.3),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1.5),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 2, 8),\n",
    "\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"eval_metric\": \"aucpr\",\n",
    "            \"random_state\": 4262,\n",
    "            \"n_jobs\": -1,\n",
    "        }\n",
    "\n",
    "        clf = xgb.XGBClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict_proba(X_val)[:, 1]\n",
    "        auprc = average_precision_score(y_val, y_pred)\n",
    "        auroc = roc_auc_score(y_val, y_pred)\n",
    "        score = 0.7 * auprc + 0.3 * auroc\n",
    "\n",
    "        trial.set_user_attr(\"auprc\", auprc)\n",
    "        trial.set_user_attr(\"auroc\", auroc)\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_optuna_cpu\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best params: {best_params}\")\n",
    "    print(f\"AUPRC: {study.best_trial.user_attrs['auprc']:.4f}, AUROC: {study.best_trial.user_attrs['auroc']:.4f}\")\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa33aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model, X_test, y_test=None):\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    if y_test is not None:\n",
    "        auprc = average_precision_score(y_test, y_pred)\n",
    "        auroc = roc_auc_score(y_test, y_pred)\n",
    "        print(f\"Test AUPRC: {auprc:.4f}, AUROC: {auroc:.4f}\")\n",
    "        return y_pred, auprc, auroc\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e94567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_groupkfold_with_oof(X, y, ids, params, n_splits=5):\n",
    "    groups = np.array([gene if gene is not None else tid for gene, tid, pos in ids])\n",
    "    gkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=4262)\n",
    "\n",
    "    models = []\n",
    "    oof_pred = np.zeros(len(y), dtype=float)\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, groups=groups), 1):\n",
    "        X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
    "        X_va, y_va = X[va_idx], y[va_idx]\n",
    "\n",
    "        clf = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            tree_method=\"hist\", \n",
    "            eval_metric=\"aucpr\", random_state=42 + fold, n_jobs=-1\n",
    "        )\n",
    "        clf.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            verbose=False\n",
    "        )\n",
    "        models.append(clf)\n",
    "\n",
    "        oof_scores = clf.predict_proba(X_va)[:, 1]\n",
    "        oof_pred[va_idx] = oof_scores\n",
    "\n",
    "        auprc = average_precision_score(y_va, oof_scores)\n",
    "        auroc = roc_auc_score(y_va, oof_scores)\n",
    "        fold_metrics.append((auprc, auroc))\n",
    "        print(f\"Fold {fold}: AUPRC={auprc:.4f}, AUROC={auroc:.4f}\")\n",
    "\n",
    "    oof_auprc = average_precision_score(y, oof_pred)\n",
    "    oof_auroc = roc_auc_score(y, oof_pred)\n",
    "    print(f\"OOF AUPRC={oof_auprc:.4f}, OOF AUROC={oof_auroc:.4f}\")\n",
    "\n",
    "    return models, oof_pred, fold_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f56a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(models, X):\n",
    "    preds = np.zeros(X.shape[0])\n",
    "    for clf in models:\n",
    "        preds += clf.predict_proba(X)[:, 1]\n",
    "    preds /= len(models)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bc0e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-02 19:53:58,250] A new study created in memory with name: xgb_optuna_cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e716c4983343d8af863b134e6148a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-02 19:54:02,993] Trial 0 finished with value: 0.6024995318345401 and parameters: {'max_depth': 7, 'learning_rate': 0.08229449313595374, 'n_estimators': 622, 'subsample': 0.8390990489676048, 'colsample_bytree': 0.7396569500445129, 'scale_pos_weight': 14, 'min_child_weight': 3, 'gamma': 0.284975859761654, 'reg_alpha': 1.4584978200320429, 'reg_lambda': 4.555576139323986}. Best is trial 0 with value: 0.6024995318345401.\n",
      "[I 2025-11-02 19:54:06,859] Trial 1 finished with value: 0.6027111474053263 and parameters: {'max_depth': 5, 'learning_rate': 0.06628729842673187, 'n_estimators': 682, 'subsample': 0.7115898772553497, 'colsample_bytree': 0.8698984855539328, 'scale_pos_weight': 11, 'min_child_weight': 5, 'gamma': 0.2822536198604645, 'reg_alpha': 1.2311260763370842, 'reg_lambda': 2.7626068714338654}. Best is trial 1 with value: 0.6027111474053263.\n",
      "[I 2025-11-02 19:54:09,811] Trial 2 finished with value: 0.5911229420021848 and parameters: {'max_depth': 4, 'learning_rate': 0.053676424537411525, 'n_estimators': 729, 'subsample': 0.7138801657459769, 'colsample_bytree': 0.7480954799443096, 'scale_pos_weight': 29, 'min_child_weight': 5, 'gamma': 0.18947439341612043, 'reg_alpha': 1.4355901421213675, 'reg_lambda': 2.2508284492312063}. Best is trial 1 with value: 0.6027111474053263.\n",
      "[I 2025-11-02 19:54:14,171] Trial 3 finished with value: 0.6006093568525603 and parameters: {'max_depth': 6, 'learning_rate': 0.03998186809198488, 'n_estimators': 717, 'subsample': 0.9109154767040734, 'colsample_bytree': 0.8484069208086873, 'scale_pos_weight': 22, 'min_child_weight': 2, 'gamma': 0.06297600692707288, 'reg_alpha': 0.8840047415028303, 'reg_lambda': 7.0816308739786935}. Best is trial 1 with value: 0.6027111474053263.\n",
      "[I 2025-11-02 19:54:16,883] Trial 4 finished with value: 0.5940402674426517 and parameters: {'max_depth': 5, 'learning_rate': 0.0611260306599032, 'n_estimators': 448, 'subsample': 0.8736197103886572, 'colsample_bytree': 0.8239658080897839, 'scale_pos_weight': 18, 'min_child_weight': 4, 'gamma': 0.15057710875138952, 'reg_alpha': 0.41909865752058284, 'reg_lambda': 3.3005763242422193}. Best is trial 1 with value: 0.6027111474053263.\n",
      "[I 2025-11-02 19:54:20,731] Trial 5 finished with value: 0.6046759515839559 and parameters: {'max_depth': 6, 'learning_rate': 0.04544992982954675, 'n_estimators': 572, 'subsample': 0.8200915034805115, 'colsample_bytree': 0.7360630199379083, 'scale_pos_weight': 10, 'min_child_weight': 6, 'gamma': 0.20078749112180244, 'reg_alpha': 1.4616093185755776, 'reg_lambda': 5.754142183063824}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:25,124] Trial 6 finished with value: 0.6045074971706726 and parameters: {'max_depth': 7, 'learning_rate': 0.03585331018391565, 'n_estimators': 531, 'subsample': 0.7293090126960096, 'colsample_bytree': 0.7454158009500357, 'scale_pos_weight': 13, 'min_child_weight': 6, 'gamma': 0.08474496793123316, 'reg_alpha': 0.12801429514216955, 'reg_lambda': 3.0511655717534554}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:29,595] Trial 7 finished with value: 0.6010545731684831 and parameters: {'max_depth': 6, 'learning_rate': 0.07220950054522113, 'n_estimators': 756, 'subsample': 0.9202388909812576, 'colsample_bytree': 0.7396586008643025, 'scale_pos_weight': 23, 'min_child_weight': 6, 'gamma': 0.0653994418187576, 'reg_alpha': 0.6682604306481281, 'reg_lambda': 4.573557031856556}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:32,742] Trial 8 finished with value: 0.5984732277685492 and parameters: {'max_depth': 5, 'learning_rate': 0.03857342646245951, 'n_estimators': 586, 'subsample': 0.7703077526471401, 'colsample_bytree': 0.9363781641731621, 'scale_pos_weight': 22, 'min_child_weight': 2, 'gamma': 0.2428983418405472, 'reg_alpha': 0.610773859082543, 'reg_lambda': 7.026483673776712}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:36,545] Trial 9 finished with value: 0.6016003139460595 and parameters: {'max_depth': 7, 'learning_rate': 0.030495842157834976, 'n_estimators': 502, 'subsample': 0.8945795437968429, 'colsample_bytree': 0.7659539479567703, 'scale_pos_weight': 30, 'min_child_weight': 6, 'gamma': 0.1483313153852862, 'reg_alpha': 0.8050513589814088, 'reg_lambda': 7.858280354346607}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:38,423] Trial 10 finished with value: 0.5879862104679139 and parameters: {'max_depth': 4, 'learning_rate': 0.04933251179205717, 'n_estimators': 404, 'subsample': 0.7978874165594979, 'colsample_bytree': 0.7030623602599155, 'scale_pos_weight': 16, 'min_child_weight': 4, 'gamma': 0.20499831888310877, 'reg_alpha': 1.0955251303384443, 'reg_lambda': 5.781918424615753}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:42,447] Trial 11 finished with value: 0.6046208418090884 and parameters: {'max_depth': 7, 'learning_rate': 0.04017470529961523, 'n_estimators': 551, 'subsample': 0.7595363479735311, 'colsample_bytree': 0.804510358004918, 'scale_pos_weight': 12, 'min_child_weight': 6, 'gamma': 0.11479780098842109, 'reg_alpha': 0.03427040855781624, 'reg_lambda': 5.6387540379822125}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:46,068] Trial 12 finished with value: 0.6030502051042586 and parameters: {'max_depth': 6, 'learning_rate': 0.04564237627985335, 'n_estimators': 598, 'subsample': 0.7690928166649152, 'colsample_bytree': 0.802085817585994, 'scale_pos_weight': 10, 'min_child_weight': 5, 'gamma': 0.12027487566321617, 'reg_alpha': 0.04910472868441604, 'reg_lambda': 5.655529998914984}. Best is trial 5 with value: 0.6046759515839559.\n",
      "[I 2025-11-02 19:54:50,188] Trial 13 finished with value: 0.6100181688208133 and parameters: {'max_depth': 7, 'learning_rate': 0.09869857153527563, 'n_estimators': 533, 'subsample': 0.8255175494192758, 'colsample_bytree': 0.792854507383613, 'scale_pos_weight': 10, 'min_child_weight': 6, 'gamma': 0.22316012113055342, 'reg_alpha': 0.3541488790739028, 'reg_lambda': 5.588871926533014}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:54:54,594] Trial 14 finished with value: 0.6084733654452246 and parameters: {'max_depth': 6, 'learning_rate': 0.08961182257947783, 'n_estimators': 645, 'subsample': 0.8403959679648074, 'colsample_bytree': 0.7816691700112165, 'scale_pos_weight': 16, 'min_child_weight': 5, 'gamma': 0.22987048599797444, 'reg_alpha': 0.3504675078213843, 'reg_lambda': 6.6033720164693985}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:00,342] Trial 15 finished with value: 0.6001301685052693 and parameters: {'max_depth': 7, 'learning_rate': 0.09939714557799002, 'n_estimators': 663, 'subsample': 0.8530371507392713, 'colsample_bytree': 0.8890887343974884, 'scale_pos_weight': 16, 'min_child_weight': 5, 'gamma': 0.2385764462385153, 'reg_alpha': 0.34509692283334925, 'reg_lambda': 6.73696250449013}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:03,761] Trial 16 finished with value: 0.5973302856827061 and parameters: {'max_depth': 6, 'learning_rate': 0.09947708242897658, 'n_estimators': 493, 'subsample': 0.8148433081091132, 'colsample_bytree': 0.7838752012042118, 'scale_pos_weight': 19, 'min_child_weight': 5, 'gamma': 0.23210729584957485, 'reg_alpha': 0.3485334974594929, 'reg_lambda': 3.9735414354411467}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:09,662] Trial 17 finished with value: 0.6015091895462907 and parameters: {'max_depth': 7, 'learning_rate': 0.08071248202148522, 'n_estimators': 666, 'subsample': 0.944791172897028, 'colsample_bytree': 0.840242447392007, 'scale_pos_weight': 25, 'min_child_weight': 3, 'gamma': 0.22385460649148012, 'reg_alpha': 0.5128593143864788, 'reg_lambda': 6.379417647192077}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:14,001] Trial 18 finished with value: 0.6028409190461669 and parameters: {'max_depth': 6, 'learning_rate': 0.08412500484824234, 'n_estimators': 617, 'subsample': 0.8567525419784955, 'colsample_bytree': 0.7801258070926099, 'scale_pos_weight': 15, 'min_child_weight': 4, 'gamma': 0.26433490754320577, 'reg_alpha': 0.23450441092642815, 'reg_lambda': 7.874315742718672}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:18,480] Trial 19 finished with value: 0.5975816074702143 and parameters: {'max_depth': 5, 'learning_rate': 0.08824725834024373, 'n_estimators': 798, 'subsample': 0.7961795765090823, 'colsample_bytree': 0.709389734175135, 'scale_pos_weight': 18, 'min_child_weight': 4, 'gamma': 0.16980959160505385, 'reg_alpha': 0.20394887665622863, 'reg_lambda': 4.95180908459125}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:22,312] Trial 20 finished with value: 0.6037907134157081 and parameters: {'max_depth': 7, 'learning_rate': 0.07360885538561956, 'n_estimators': 474, 'subsample': 0.8796424405371768, 'colsample_bytree': 0.8094251282824081, 'scale_pos_weight': 13, 'min_child_weight': 5, 'gamma': 0.25835930926072925, 'reg_alpha': 0.9247123496993859, 'reg_lambda': 6.2227711675245025}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:25,954] Trial 21 finished with value: 0.6049030978391223 and parameters: {'max_depth': 6, 'learning_rate': 0.056956539261474315, 'n_estimators': 560, 'subsample': 0.8152357565171133, 'colsample_bytree': 0.7719535380880844, 'scale_pos_weight': 10, 'min_child_weight': 6, 'gamma': 0.20830585211719216, 'reg_alpha': 0.508430804352686, 'reg_lambda': 5.233673149796016}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:29,621] Trial 22 finished with value: 0.6062280249877813 and parameters: {'max_depth': 6, 'learning_rate': 0.05801330839598445, 'n_estimators': 553, 'subsample': 0.8349342344611917, 'colsample_bytree': 0.7702459926035542, 'scale_pos_weight': 12, 'min_child_weight': 6, 'gamma': 0.2141797734106862, 'reg_alpha': 0.5174399291366789, 'reg_lambda': 5.0809619204824745}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:33,190] Trial 23 finished with value: 0.6005008904110722 and parameters: {'max_depth': 6, 'learning_rate': 0.09108395255788408, 'n_estimators': 526, 'subsample': 0.8454317661760907, 'colsample_bytree': 0.7893205189187167, 'scale_pos_weight': 12, 'min_child_weight': 6, 'gamma': 0.1762666058535272, 'reg_alpha': 0.5511138552696877, 'reg_lambda': 3.7657998597291398}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:37,046] Trial 24 finished with value: 0.6001370597406916 and parameters: {'max_depth': 5, 'learning_rate': 0.07287650037066028, 'n_estimators': 637, 'subsample': 0.7987599817018781, 'colsample_bytree': 0.8278884933340208, 'scale_pos_weight': 16, 'min_child_weight': 5, 'gamma': 0.2182565122551043, 'reg_alpha': 0.293647687433488, 'reg_lambda': 4.854850475691531}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:40,098] Trial 25 finished with value: 0.6008745397720676 and parameters: {'max_depth': 6, 'learning_rate': 0.06673406246497668, 'n_estimators': 447, 'subsample': 0.8698035063502689, 'colsample_bytree': 0.7645281465267569, 'scale_pos_weight': 14, 'min_child_weight': 6, 'gamma': 0.25768861584543296, 'reg_alpha': 0.715596823350971, 'reg_lambda': 6.327617046982533}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:44,409] Trial 26 finished with value: 0.6005428315708932 and parameters: {'max_depth': 7, 'learning_rate': 0.09237090877169976, 'n_estimators': 536, 'subsample': 0.8318139277727462, 'colsample_bytree': 0.724873200407544, 'scale_pos_weight': 12, 'min_child_weight': 5, 'gamma': 0.296981036696685, 'reg_alpha': 0.4342833545696493, 'reg_lambda': 7.394865424985776}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:48,838] Trial 27 finished with value: 0.5999348760379317 and parameters: {'max_depth': 6, 'learning_rate': 0.07782813357940159, 'n_estimators': 643, 'subsample': 0.7850842399423007, 'colsample_bytree': 0.8650827401318123, 'scale_pos_weight': 17, 'min_child_weight': 6, 'gamma': 0.1853246723893897, 'reg_alpha': 0.1813480189741626, 'reg_lambda': 4.206484965629217}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:52,459] Trial 28 finished with value: 0.5951226744563929 and parameters: {'max_depth': 5, 'learning_rate': 0.06365182799268734, 'n_estimators': 583, 'subsample': 0.7458947703966373, 'colsample_bytree': 0.7598118958988481, 'scale_pos_weight': 20, 'min_child_weight': 5, 'gamma': 0.24645747405638274, 'reg_alpha': 0.4162445677000678, 'reg_lambda': 5.352903880155332}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:55:57,584] Trial 29 finished with value: 0.603192439484959 and parameters: {'max_depth': 7, 'learning_rate': 0.08412259133042381, 'n_estimators': 611, 'subsample': 0.835214349161041, 'colsample_bytree': 0.7994648984985978, 'scale_pos_weight': 14, 'min_child_weight': 3, 'gamma': 0.27863712338474134, 'reg_alpha': 0.6209426309448884, 'reg_lambda': 6.178723597370549}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:03,315] Trial 30 finished with value: 0.601669898938902 and parameters: {'max_depth': 7, 'learning_rate': 0.09417054943959, 'n_estimators': 694, 'subsample': 0.8586239039985496, 'colsample_bytree': 0.8222131743297345, 'scale_pos_weight': 14, 'min_child_weight': 6, 'gamma': 0.16518436078799617, 'reg_alpha': 0.8033416952099202, 'reg_lambda': 4.468209119010902}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:07,142] Trial 31 finished with value: 0.6077681266238478 and parameters: {'max_depth': 6, 'learning_rate': 0.055525282484647644, 'n_estimators': 560, 'subsample': 0.8122471459128239, 'colsample_bytree': 0.7776992774757442, 'scale_pos_weight': 10, 'min_child_weight': 6, 'gamma': 0.21500392627311987, 'reg_alpha': 0.5077373500108746, 'reg_lambda': 5.2268504634250545}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:10,561] Trial 32 finished with value: 0.6083660622783389 and parameters: {'max_depth': 6, 'learning_rate': 0.05816623929698996, 'n_estimators': 508, 'subsample': 0.8206407541046781, 'colsample_bytree': 0.7832405744168138, 'scale_pos_weight': 11, 'min_child_weight': 6, 'gamma': 0.2180754958729302, 'reg_alpha': 0.2868316841234825, 'reg_lambda': 5.345367810347907}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:13,980] Trial 33 finished with value: 0.5950619184748465 and parameters: {'max_depth': 6, 'learning_rate': 0.053319044010814116, 'n_estimators': 500, 'subsample': 0.8097600329841343, 'colsample_bytree': 0.7851967810487609, 'scale_pos_weight': 11, 'min_child_weight': 5, 'gamma': 0.19284094272201624, 'reg_alpha': 0.3147297372073664, 'reg_lambda': 6.717748355724864}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:16,696] Trial 34 finished with value: 0.6006516548121631 and parameters: {'max_depth': 5, 'learning_rate': 0.049802162490320524, 'n_estimators': 472, 'subsample': 0.7850254892142026, 'colsample_bytree': 0.7507381204956138, 'scale_pos_weight': 10, 'min_child_weight': 6, 'gamma': 0.22702444607688294, 'reg_alpha': 0.1488275206754734, 'reg_lambda': 5.470017270579417}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:19,337] Trial 35 finished with value: 0.5946377149404835 and parameters: {'max_depth': 4, 'learning_rate': 0.06102738128735874, 'n_estimators': 518, 'subsample': 0.8276259541623726, 'colsample_bytree': 0.8175334707744553, 'scale_pos_weight': 11, 'min_child_weight': 5, 'gamma': 0.2795507920524121, 'reg_alpha': 0.42480918170417936, 'reg_lambda': 5.965666682683747}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:22,153] Trial 36 finished with value: 0.5954811839611092 and parameters: {'max_depth': 6, 'learning_rate': 0.06719212260125652, 'n_estimators': 415, 'subsample': 0.8439519361729226, 'colsample_bytree': 0.7260402597885661, 'scale_pos_weight': 27, 'min_child_weight': 6, 'gamma': 0.2508116206290174, 'reg_alpha': 0.26661106815203495, 'reg_lambda': 2.2342270439337377}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:25,706] Trial 37 finished with value: 0.6043486792732761 and parameters: {'max_depth': 5, 'learning_rate': 0.04523580440988959, 'n_estimators': 630, 'subsample': 0.8891580257446969, 'colsample_bytree': 0.8365922727147448, 'scale_pos_weight': 13, 'min_child_weight': 6, 'gamma': 0.19529295808127392, 'reg_alpha': 0.37780684916169577, 'reg_lambda': 4.773996239444751}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:30,505] Trial 38 finished with value: 0.6023556432156608 and parameters: {'max_depth': 6, 'learning_rate': 0.05107026567820967, 'n_estimators': 703, 'subsample': 0.8060599609938128, 'colsample_bytree': 0.8580098840106292, 'scale_pos_weight': 11, 'min_child_weight': 3, 'gamma': 0.27073665456350454, 'reg_alpha': 0.12320127987020732, 'reg_lambda': 6.5923071735579795}. Best is trial 13 with value: 0.6100181688208133.\n",
      "[I 2025-11-02 19:56:34,427] Trial 39 finished with value: 0.6078828114184227 and parameters: {'max_depth': 6, 'learning_rate': 0.0691408562794786, 'n_estimators': 569, 'subsample': 0.8238946777101447, 'colsample_bytree': 0.7927947749768163, 'scale_pos_weight': 15, 'min_child_weight': 5, 'gamma': 0.23106697919508437, 'reg_alpha': 1.263909999581199, 'reg_lambda': 7.382207470628427}. Best is trial 13 with value: 0.6100181688208133.\n",
      "Best params: {'max_depth': 7, 'learning_rate': 0.09869857153527563, 'n_estimators': 533, 'subsample': 0.8255175494192758, 'colsample_bytree': 0.792854507383613, 'scale_pos_weight': 10, 'min_child_weight': 6, 'gamma': 0.22316012113055342, 'reg_alpha': 0.3541488790739028, 'reg_lambda': 5.588871926533014}\n",
      "AUPRC: 0.4764, AUROC: 0.9219\n"
     ]
    }
   ],
   "source": [
    "best_params = train_and_validate_optuna(X_train, y_train, X_val, y_val, n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3763e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: AUPRC=0.4808, AUROC=0.9213\n",
      "Fold 2: AUPRC=0.4753, AUROC=0.9210\n",
      "Fold 3: AUPRC=0.4968, AUROC=0.9317\n",
      "Fold 4: AUPRC=0.4845, AUROC=0.9216\n",
      "Fold 5: AUPRC=0.4916, AUROC=0.9184\n",
      "OOF AUPRC=0.4833, OOF AUROC=0.9228\n"
     ]
    }
   ],
   "source": [
    "X_final = np.concatenate([X_train]) ##previously we include validation data, but now we remove it to avoid overfitting\n",
    "y_final = np.concatenate([y_train])\n",
    "ids_final = ids_train\n",
    "models, oof_pred, _ = train_final_groupkfold_with_oof(\n",
    "    X_final, y_final, ids_final, best_params, n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f84ad8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test AUPRC=0.5273, AUROC=0.9338\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_ensemble(models, X_test)\n",
    "auprc = average_precision_score(y_test, y_pred)\n",
    "auroc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"Final Test AUPRC={auprc:.4f}, AUROC={auroc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03503a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62505524",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"models/final\").mkdir(parents=True, exist_ok=True)\n",
    "for i, model in enumerate(models):\n",
    "    joblib.dump(model, f\"models/final/xgb_fold{i+1}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0662fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sanity check before proceeding\n",
    "def predict_ensemble_dataset(models, data_path, label_dict=None, transcript_to_gene=None, output_csv=\"predictions/pred_dataset0.csv\"):\n",
    "    preds = np.array([m.predict_proba(X)[:,1] for m in models])\n",
    "    y_pred = preds.mean(axis=0)  # mean ensemble\n",
    "    print(y_pred.shape)\n",
    "\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"gene_id\": [gene for gene, tid, pos in ids],\n",
    "        \"transcript_id\": [tid for gene, tid, pos in ids],\n",
    "        \"transcript_position\": [pos for gene, tid, pos in ids],\n",
    "        \"score\": y_pred\n",
    "    })\n",
    "    Path(output_csv).parent.mkdir(parents=True, exist_ok=True)\n",
    "    pred_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved predictions to {output_csv}\")\n",
    "    \n",
    "    if label_dict:\n",
    "        mask = ~pd.isna(y)\n",
    "        if mask.sum() > 0:\n",
    "            y_true = y[mask].astype(int)\n",
    "            y_pred_masked = y_pred[mask]\n",
    "            auprc = average_precision_score(y_true, y_pred_masked)\n",
    "            auroc = roc_auc_score(y_true, y_pred_masked)\n",
    "            print(f\"len before masking: {len(y)}; len after masking: {len(y_true)}\")\n",
    "            print(f\"[Sanity check on labeled data] AUPRC={auprc:.4f}, AUROC={auroc:.4f}\")\n",
    "\n",
    "    return pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2249553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121838,)\n",
      "Saved predictions to predictions/pred_dataset0.csv\n",
      "len before masking: 121838; len after masking: 121838\n",
      "[Sanity check on labeled data] AUPRC=0.8648, AUROC=0.9802\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data_task1/dataset_0.json\"\n",
    "pred_df = predict_ensemble_dataset(models, data_path, label_dict, transcript_to_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad39b233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121838, 73)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
